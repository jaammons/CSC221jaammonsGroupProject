import requests
import pandas as pd
from bs4 import BeautifulSoup

# URL of the 2023 FedEx Cup Playoffs Wikipedia page
url = 'https://en.wikipedia.org/wiki/2023_FedEx_Cup_Playoffs'

# Send a GET request to the URL
response = requests.get(url)

# Parse the HTML content using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find the table containing the FedEx Cup Playoffs data
# Assuming the data is in the table with class 'wikitable'
table = soup.find('table', {'class': 'wikitable'})

# Extract table data into a list of lists
data = []
for row in table.find_all('tr'):
    row_data = [cell.get_text(strip=True) for cell in row.find_all(['th', 'td'])]
    if row_data:
        data.append(row_data)

# Display the first 10 rows as a table using pandas
df = pd.DataFrame(data[1:], columns=data[0])
display(df.head(10))

# Save the data to a CSV file
csv_filename = 'CSC221-webscrape-data.csv'
df.to_csv(csv_filename, index=False)

print(f"Data saved to {csv_filename}")
